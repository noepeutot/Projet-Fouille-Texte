{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# üçΩÔ∏è Projet Fouille d'Opinions - Classification Multi-Aspects\n",
        "\n",
        "Ce notebook entra√Æne un classificateur CamemBERT pour pr√©dire les opinions sur 3 aspects de restaurants:\n",
        "- **Prix** : prix des plats et boissons\n",
        "- **Cuisine** : qualit√© de la nourriture\n",
        "- **Service** : qualit√© du service\n",
        "\n",
        "**Instructions:**\n",
        "1. Allez dans `Runtime` > `Change runtime type` > S√©lectionnez `T4 GPU`\n",
        "2. Uploadez vos fichiers de donn√©es dans le r√©pertoire `/content/data/`\n",
        "3. Ex√©cutez toutes les cellules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install"
      },
      "source": [
        "## 1. Installation des d√©pendances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets torch lightning pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_section"
      },
      "source": [
        "## 2. Upload des donn√©es\n",
        "\n",
        "Ex√©cutez cette cellule et uploadez vos fichiers:\n",
        "- `ftdataset_train.tsv`\n",
        "- `ftdataset_val.tsv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_files"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Cr√©er le r√©pertoire data\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "\n",
        "print(\"Uploadez vos fichiers de donn√©es (ftdataset_train.tsv et ftdataset_val.tsv):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# D√©placer les fichiers vers le r√©pertoire data\n",
        "for filename in uploaded.keys():\n",
        "    os.rename(filename, f'/content/data/{filename}')\n",
        "    print(f\"Fichier {filename} d√©plac√© vers /content/data/\")\n",
        "\n",
        "# V√©rifier les fichiers\n",
        "print(\"\\nFichiers dans /content/data:\")\n",
        "!ls -la /content/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_utils_section"
      },
      "source": [
        "## 3. D√©finition des utilitaires de donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_utils"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "# Mapping des labels vers indices pour les 4 classes d'opinion\n",
        "LABEL_TO_IDX = {\n",
        "    \"Positive\": 0,\n",
        "    \"N√©gative\": 1,\n",
        "    \"Neutre\": 2,\n",
        "    \"NE\": 3\n",
        "}\n",
        "\n",
        "# Mapping inverse : indices vers labels\n",
        "IDX_TO_LABEL = {v: k for k, v in LABEL_TO_IDX.items()}\n",
        "\n",
        "# Liste des aspects √† classifier\n",
        "ASPECTS = [\"Prix\", \"Cuisine\", \"Service\"]\n",
        "\n",
        "\n",
        "class OpinionDataset(Dataset):\n",
        "    \"\"\"Dataset PyTorch pour les avis de restaurants.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        texts: list[str],\n",
        "        tokenizer: PreTrainedTokenizer,\n",
        "        labels: Optional[dict[str, list[int]]] = None,\n",
        "        max_length: int = 256\n",
        "    ):\n",
        "        self.encodings = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        item = {\n",
        "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
        "        }\n",
        "\n",
        "        if self.labels is not None:\n",
        "            for aspect in ASPECTS:\n",
        "                item[f\"label_{aspect.lower()}\"] = torch.tensor(\n",
        "                    self.labels[aspect][idx], dtype=torch.long\n",
        "                )\n",
        "\n",
        "        return item\n",
        "\n",
        "\n",
        "def prepare_labels(data: list[dict]) -> dict[str, list[int]]:\n",
        "    \"\"\"Pr√©pare les labels num√©riques √† partir des donn√©es d'entra√Ænement.\"\"\"\n",
        "    labels = {aspect: [] for aspect in ASPECTS}\n",
        "\n",
        "    for item in data:\n",
        "        for aspect in ASPECTS:\n",
        "            label_text = item[aspect]\n",
        "            if label_text in LABEL_TO_IDX:\n",
        "                labels[aspect].append(LABEL_TO_IDX[label_text])\n",
        "            else:\n",
        "                labels[aspect].append(LABEL_TO_IDX[\"NE\"])\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def get_texts(data: list[dict]) -> list[str]:\n",
        "    \"\"\"Extrait les textes d'avis des donn√©es.\"\"\"\n",
        "    return [item[\"Avis\"] for item in data]\n",
        "\n",
        "\n",
        "class DataCollatorWithPadding:\n",
        "    \"\"\"Collator pour le padding dynamique des batches.\"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer, padding: bool = True):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.padding = padding\n",
        "\n",
        "    def __call__(self, features: list[dict]) -> dict:\n",
        "        batch = {\n",
        "            \"input_ids\": torch.stack([f[\"input_ids\"] for f in features]),\n",
        "            \"attention_mask\": torch.stack([f[\"attention_mask\"] for f in features]),\n",
        "        }\n",
        "\n",
        "        for aspect in ASPECTS:\n",
        "            key = f\"label_{aspect.lower()}\"\n",
        "            if key in features[0]:\n",
        "                batch[key] = torch.stack([f[key] for f in features])\n",
        "\n",
        "        return batch\n",
        "\n",
        "print(\"‚úÖ Utilitaires de donn√©es charg√©s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_section"
      },
      "source": [
        "## 4. D√©finition du mod√®le CamemBERT Multi-T√™tes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_definition"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "class MultiHeadClassifier(nn.Module):\n",
        "    \"\"\"Mod√®le de classification multi-aspects bas√© sur CamemBERT.\"\"\"\n",
        "\n",
        "    def __init__(self, plm_name: str = \"camembert-base\", num_classes: int = 4, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = AutoConfig.from_pretrained(plm_name)\n",
        "        self.encoder = AutoModel.from_pretrained(plm_name)\n",
        "\n",
        "        hidden_size = self.config.hidden_size\n",
        "\n",
        "        # T√™tes de classification pour chaque aspect\n",
        "        self.classifier_prix = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "        self.classifier_cuisine = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "        self.classifier_service = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "        self.classifiers = {\n",
        "            \"Prix\": self.classifier_prix,\n",
        "            \"Cuisine\": self.classifier_cuisine,\n",
        "            \"Service\": self.classifier_service\n",
        "        }\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> dict[str, torch.Tensor]:\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        logits = {\n",
        "            \"Prix\": self.classifier_prix(cls_output),\n",
        "            \"Cuisine\": self.classifier_cuisine(cls_output),\n",
        "            \"Service\": self.classifier_service(cls_output)\n",
        "        }\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "class PLMClassifier:\n",
        "    \"\"\"Wrapper pour le classificateur d'opinions multi-aspects.\"\"\"\n",
        "\n",
        "    def __init__(self, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "        self.plm_name = \"camembert-base\"\n",
        "        self.num_classes = 4\n",
        "        self.max_length = 256\n",
        "        self.batch_size = 16\n",
        "        self.learning_rate = 2e-5\n",
        "        self.num_epochs = 3\n",
        "        self.warmup_ratio = 0.1\n",
        "        self.device = torch.device(device)\n",
        "\n",
        "        print(f\"Chargement de CamemBERT...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.plm_name)\n",
        "        self.model = MultiHeadClassifier(\n",
        "            plm_name=self.plm_name,\n",
        "            num_classes=self.num_classes,\n",
        "            dropout=0.1\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        print(f\"‚úÖ Mod√®le charg√© sur {self.device}\")\n",
        "\n",
        "    def train(self, train_data: list[dict], val_data: list[dict]) -> None:\n",
        "        print(f\"\\nüìä Entra√Ænement sur {self.device}\")\n",
        "        print(f\"  - Exemples d'entra√Ænement: {len(train_data)}\")\n",
        "        print(f\"  - Exemples de validation: {len(val_data)}\")\n",
        "\n",
        "        train_texts = get_texts(train_data)\n",
        "        train_labels = prepare_labels(train_data)\n",
        "        val_texts = get_texts(val_data)\n",
        "        val_labels = prepare_labels(val_data)\n",
        "\n",
        "        train_dataset = OpinionDataset(train_texts, self.tokenizer, labels=train_labels, max_length=self.max_length)\n",
        "        val_dataset = OpinionDataset(val_texts, self.tokenizer, labels=val_labels, max_length=self.max_length)\n",
        "\n",
        "        collator = DataCollatorWithPadding(self.tokenizer)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=collator)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=collator)\n",
        "\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "        total_steps = len(train_loader) * self.num_epochs\n",
        "        warmup_steps = int(total_steps * self.warmup_ratio)\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            print(f\"\\n--- Epoch {epoch + 1}/{self.num_epochs} ---\")\n",
        "\n",
        "            self.model.train()\n",
        "            total_train_loss = 0.0\n",
        "\n",
        "            progress_bar = tqdm(train_loader, desc=\"Training\")\n",
        "\n",
        "            for batch in progress_bar:\n",
        "                input_ids = batch[\"input_ids\"].to(self.device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
        "\n",
        "                logits = self.model(input_ids, attention_mask)\n",
        "\n",
        "                loss = 0.0\n",
        "                for aspect in ASPECTS:\n",
        "                    labels = batch[f\"label_{aspect.lower()}\"].to(self.device)\n",
        "                    loss += self.criterion(logits[aspect], labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                total_train_loss += loss.item()\n",
        "                progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(train_loader)\n",
        "            print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "            val_acc = self._evaluate(val_loader)\n",
        "            print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "\n",
        "        print(f\"\\nüèÜ Meilleure exactitude de validation: {best_val_acc:.2f}%\")\n",
        "\n",
        "    def _evaluate(self, dataloader: DataLoader) -> float:\n",
        "        self.model.eval()\n",
        "        correct_counts = {aspect: 0 for aspect in ASPECTS}\n",
        "        total_counts = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                input_ids = batch[\"input_ids\"].to(self.device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
        "\n",
        "                logits = self.model(input_ids, attention_mask)\n",
        "\n",
        "                for aspect in ASPECTS:\n",
        "                    labels = batch[f\"label_{aspect.lower()}\"].to(self.device)\n",
        "                    preds = torch.argmax(logits[aspect], dim=-1)\n",
        "                    correct_counts[aspect] += (preds == labels).sum().item()\n",
        "\n",
        "                total_counts += input_ids.size(0)\n",
        "\n",
        "        accuracies = {aspect: 100 * correct_counts[aspect] / total_counts for aspect in ASPECTS}\n",
        "        avg_accuracy = sum(accuracies.values()) / len(ASPECTS)\n",
        "\n",
        "        return avg_accuracy\n",
        "\n",
        "    def predict(self, texts: list[str]) -> list[dict[str, str]]:\n",
        "        self.model.eval()\n",
        "        all_predictions = []\n",
        "        batch_size = 32\n",
        "\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "            encodings = self.tokenizer(\n",
        "                batch_texts,\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=self.max_length,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            input_ids = encodings[\"input_ids\"].to(self.device)\n",
        "            attention_mask = encodings[\"attention_mask\"].to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = self.model(input_ids, attention_mask)\n",
        "\n",
        "            for j in range(len(batch_texts)):\n",
        "                prediction = {}\n",
        "                for aspect in ASPECTS:\n",
        "                    pred_idx = torch.argmax(logits[aspect][j]).item()\n",
        "                    prediction[aspect] = IDX_TO_LABEL[pred_idx]\n",
        "                all_predictions.append(prediction)\n",
        "\n",
        "        return all_predictions\n",
        "\n",
        "print(\"‚úÖ Mod√®le d√©fini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_data_section"
      },
      "source": [
        "## 5. Chargement des donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger les donn√©es\n",
        "df_train = pd.read_csv(\"/content/data/ftdataset_train.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
        "df_val = pd.read_csv(\"/content/data/ftdataset_val.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
        "\n",
        "train_data = df_train.to_dict(orient='records')\n",
        "val_data = df_val.to_dict(orient='records')\n",
        "\n",
        "print(f\"‚úÖ Donn√©es charg√©es:\")\n",
        "print(f\"  - Train: {len(train_data)} exemples\")\n",
        "print(f\"  - Validation: {len(val_data)} exemples\")\n",
        "print(f\"\\nExemple d'avis:\")\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "## 6. Entra√Ænement du mod√®le üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training"
      },
      "outputs": [],
      "source": [
        "# Initialiser et entra√Æner le classificateur\n",
        "classifier = PLMClassifier()\n",
        "classifier.train(train_data, val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval_section"
      },
      "source": [
        "## 7. √âvaluation finale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluation"
      },
      "outputs": [],
      "source": [
        "# √âvaluation sur les donn√©es de validation\n",
        "print(\"\\nüìà √âvaluation finale sur les donn√©es de validation...\")\n",
        "\n",
        "val_texts = get_texts(val_data)\n",
        "predictions = classifier.predict(val_texts)\n",
        "\n",
        "# Calculer les m√©triques\n",
        "correct_counts = {aspect: 0 for aspect in ASPECTS}\n",
        "n = len(val_data)\n",
        "\n",
        "for pred, ref in zip(predictions, val_data):\n",
        "    for aspect in ASPECTS:\n",
        "        if pred[aspect] == ref[aspect]:\n",
        "            correct_counts[aspect] += 1\n",
        "\n",
        "print(\"\\nüìä R√©sultats par aspect:\")\n",
        "for aspect in ASPECTS:\n",
        "    acc = 100 * correct_counts[aspect] / n\n",
        "    print(f\"  - {aspect}: {acc:.2f}%\")\n",
        "\n",
        "macro_acc = sum(100 * correct_counts[aspect] / n for aspect in ASPECTS) / len(ASPECTS)\n",
        "print(f\"\\nüéØ Exactitude moyenne (macro_acc): {macro_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_section"
      },
      "source": [
        "## 8. Test sur quelques exemples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_examples"
      },
      "outputs": [],
      "source": [
        "# Tester sur quelques exemples\n",
        "test_texts = [\n",
        "    \"Excellente cuisine, plats savoureux et copieux. Le service √©tait un peu lent mais correct. Prix raisonnables.\",\n",
        "    \"Tr√®s d√©√ßu par ce restaurant. La nourriture √©tait froide et le serveur d√©sagr√©able. Bien trop cher pour ce que c'est.\",\n",
        "    \"Bon rapport qualit√©-prix. Service efficace et souriant. La cuisine √©tait correcte sans √™tre exceptionnelle.\"\n",
        "]\n",
        "\n",
        "print(\"\\nüß™ Test sur quelques exemples:\\n\")\n",
        "predictions = classifier.predict(test_texts)\n",
        "\n",
        "for text, pred in zip(test_texts, predictions):\n",
        "    print(f\"üìù Avis: {text[:80]}...\")\n",
        "    print(f\"   ‚Üí Prix: {pred['Prix']}, Cuisine: {pred['Cuisine']}, Service: {pred['Service']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_section"
      },
      "source": [
        "## 9. Sauvegarde du mod√®le (optionnel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_model"
      },
      "outputs": [],
      "source": [
        "# Sauvegarder le mod√®le\n",
        "torch.save(classifier.model.state_dict(), '/content/model_weights.pt')\n",
        "print(\"‚úÖ Mod√®le sauvegard√© dans /content/model_weights.pt\")\n",
        "\n",
        "# T√©l√©charger le mod√®le\n",
        "from google.colab import files\n",
        "files.download('/content/model_weights.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
