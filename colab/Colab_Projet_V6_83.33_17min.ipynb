{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# üçΩÔ∏è Projet Fouille d'Opinions - V6 OPTIMIS√â+\n",
        "\n",
        "| Version | Temps | Accuracy |\n",
        "|---------|-------|----------|\n",
        "| V2 (large) | ~50 min | 88.72% |\n",
        "| V5 (base) | ~12 min | 83.33% |\n",
        "| **V6 (base+)** | **~15-18 min** | **~84-85%** |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available(): print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CONFIG V6 - Optimis√© pour meilleure accuracy\n",
        "# ============================================\n",
        "CONFIG = {\n",
        "    \"model_name\": \"camembert-base\",\n",
        "    \"num_epochs\": 6,          # +1 epoch\n",
        "    \"batch_size\": 16,\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"max_length\": 256,        # Plus de contexte\n",
        "    \"dropout\": 0.1,\n",
        "    \"label_smoothing\": 0.1,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"warmup_ratio\": 0.1,\n",
        "    \"hidden_dim\": 256,\n",
        "    \"patience\": 3,            # Plus de patience\n",
        "}\n",
        "print(\"üìã Config V6:\", CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "print(\"Uploadez ftdataset_train.tsv et ftdataset_val.tsv:\")\n",
        "for f in files.upload().keys():\n",
        "    os.rename(f, f'/content/data/{f}')\n",
        "!ls /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "all_code"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoTokenizer, AutoModel, get_cosine_schedule_with_warmup\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "LABEL_TO_IDX = {\"Positive\": 0, \"N√©gative\": 1, \"Neutre\": 2, \"NE\": 3}\n",
        "IDX_TO_LABEL = {v: k for k, v in LABEL_TO_IDX.items()}\n",
        "ASPECTS = [\"Prix\", \"Cuisine\", \"Service\"]\n",
        "\n",
        "class OpinionDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, labels=None, max_length=256):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        self.labels = labels\n",
        "    def __len__(self): return len(self.encodings[\"input_ids\"])\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\"input_ids\": self.encodings[\"input_ids\"][idx], \"attention_mask\": self.encodings[\"attention_mask\"][idx]}\n",
        "        if self.labels:\n",
        "            for a in ASPECTS: item[f\"label_{a.lower()}\"] = torch.tensor(self.labels[a][idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "def prepare_labels(data): return {a: [LABEL_TO_IDX.get(d[a], 3) for d in data] for a in ASPECTS}\n",
        "def get_texts(data): return [d[\"Avis\"] for d in data]\n",
        "def collate_fn(f):\n",
        "    b = {\"input_ids\": torch.stack([x[\"input_ids\"] for x in f]), \"attention_mask\": torch.stack([x[\"attention_mask\"] for x in f])}\n",
        "    for a in ASPECTS:\n",
        "        k = f\"label_{a.lower()}\"\n",
        "        if k in f[0]: b[k] = torch.stack([x[k] for x in f])\n",
        "    return b\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, model_name, hidden_dim=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        hs = self.encoder.config.hidden_size\n",
        "        self.classifiers = nn.ModuleDict({\n",
        "            a: nn.Sequential(nn.Dropout(dropout), nn.Linear(hs, hidden_dim), nn.GELU(), nn.Dropout(dropout), nn.Linear(hidden_dim, 4))\n",
        "            for a in ASPECTS\n",
        "        })\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls = out.last_hidden_state[:, 0, :]\n",
        "        return {a: self.classifiers[a](cls) for a in ASPECTS}\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"üîß Chargement de {config['model_name']}...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
        "        self.model = Classifier(config['model_name'], config['hidden_dim'], config['dropout']).to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
        "        print(f\"‚úÖ Mod√®le sur {self.device}\")\n",
        "\n",
        "    def train(self, train_data, val_data):\n",
        "        cfg = self.config\n",
        "        start = time.time()\n",
        "        train_ds = OpinionDataset(get_texts(train_data), self.tokenizer, prepare_labels(train_data), cfg['max_length'])\n",
        "        val_ds = OpinionDataset(get_texts(val_data), self.tokenizer, prepare_labels(val_data), cfg['max_length'])\n",
        "        train_loader = DataLoader(train_ds, batch_size=cfg['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "        val_loader = DataLoader(val_ds, batch_size=cfg['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
        "        \n",
        "        optimizer = AdamW(self.model.parameters(), lr=cfg['learning_rate'], weight_decay=cfg['weight_decay'])\n",
        "        total_steps = len(train_loader) * cfg['num_epochs']\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, int(total_steps * cfg['warmup_ratio']), total_steps)\n",
        "        \n",
        "        best_acc, best_state, patience = 0, None, 0\n",
        "        \n",
        "        for epoch in range(cfg['num_epochs']):\n",
        "            t0 = time.time()\n",
        "            print(f\"\\n{'='*50}\\nEpoch {epoch+1}/{cfg['num_epochs']}\\n{'='*50}\")\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "            for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "                ids, mask = batch[\"input_ids\"].to(self.device), batch[\"attention_mask\"].to(self.device)\n",
        "                logits = self.model(ids, mask)\n",
        "                loss = sum(self.criterion(logits[a], batch[f\"label_{a.lower()}\"].to(self.device)) for a in ASPECTS)\n",
        "                optimizer.zero_grad(); loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "                optimizer.step(); scheduler.step()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "            print(f\"Loss: {total_loss/len(train_loader):.4f}\")\n",
        "            acc, det = self._eval(val_loader)\n",
        "            print(f\"Val: {acc:.2f}% | {det} | ‚è±Ô∏è {time.time()-t0:.0f}s\")\n",
        "            \n",
        "            if acc > best_acc:\n",
        "                best_acc, best_state, patience = acc, {k: v.cpu().clone() for k, v in self.model.state_dict().items()}, 0\n",
        "                print(\"‚≠ê Best!\")\n",
        "            else:\n",
        "                patience += 1\n",
        "                print(f\"‚è≥ Patience: {patience}/{cfg['patience']}\")\n",
        "                if patience >= cfg['patience']: print(\"‚ö†Ô∏è Early stop\"); break\n",
        "        \n",
        "        if best_state: self.model.load_state_dict(best_state); self.model.to(self.device)\n",
        "        total_time = time.time() - start\n",
        "        print(f\"\\nüèÜ BEST: {best_acc:.2f}% | ‚è±Ô∏è {total_time/60:.1f} min\")\n",
        "        return best_acc, total_time\n",
        "\n",
        "    def _eval(self, loader):\n",
        "        self.model.eval()\n",
        "        correct, total = {a: 0 for a in ASPECTS}, 0\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                ids, mask = batch[\"input_ids\"].to(self.device), batch[\"attention_mask\"].to(self.device)\n",
        "                logits = self.model(ids, mask)\n",
        "                for a in ASPECTS:\n",
        "                    correct[a] += (torch.argmax(logits[a], -1) == batch[f\"label_{a.lower()}\"].to(self.device)).sum().item()\n",
        "                total += ids.size(0)\n",
        "        det = {a: round(100*correct[a]/total, 1) for a in ASPECTS}\n",
        "        return sum(det.values())/3, det\n",
        "\n",
        "    def predict(self, texts):\n",
        "        self.model.eval()\n",
        "        preds = []\n",
        "        for i in range(0, len(texts), 32):\n",
        "            enc = self.tokenizer(texts[i:i+32], truncation=True, padding=True, max_length=self.config['max_length'], return_tensors=\"pt\")\n",
        "            with torch.no_grad():\n",
        "                logits = self.model(enc[\"input_ids\"].to(self.device), enc[\"attention_mask\"].to(self.device))\n",
        "            for j in range(len(texts[i:i+32])):\n",
        "                preds.append({a: IDX_TO_LABEL[torch.argmax(logits[a][j]).item()] for a in ASPECTS})\n",
        "        return preds\n",
        "\n",
        "print(\"‚úÖ Tout pr√™t!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/content/data/ftdataset_train.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
        "df_val = pd.read_csv(\"/content/data/ftdataset_val.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
        "train_data, val_data = df_train.to_dict('records'), df_val.to_dict('records')\n",
        "print(f\"‚úÖ Train={len(train_data)}, Val={len(val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(CONFIG)\n",
        "best_acc, total_time = trainer.train(train_data, val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eval"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìà √âvaluation finale...\")\n",
        "preds = trainer.predict(get_texts(val_data))\n",
        "correct = {a: sum(1 for p, r in zip(preds, val_data) if p[a] == r[a]) for a in ASPECTS}\n",
        "n = len(val_data)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä R√âSULTATS V6\")\n",
        "print(\"=\"*50)\n",
        "for a in ASPECTS: print(f\"  {a}: {100*correct[a]/n:.2f}%\")\n",
        "macro = sum(100*correct[a]/n for a in ASPECTS)/3\n",
        "print(f\"\\nüéØ MACRO: {macro:.2f}% | ‚è±Ô∏è {total_time/60:.1f} min\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save"
      },
      "outputs": [],
      "source": [
        "torch.save({'model': trainer.model.state_dict(), 'config': CONFIG, 'acc': best_acc}, '/content/model_v6.pt')\n",
        "print(f\"‚úÖ Sauvegard√©\")\n",
        "from google.colab import files\n",
        "files.download('/content/model_v6.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {"gpuType": "T4", "provenance": []},
    "kernelspec": {"display_name": "Python 3", "name": "python3"}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
