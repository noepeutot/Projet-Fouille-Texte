{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# üçΩÔ∏è Projet Fouille d'Opinions - V4 OPTIMIS√â (Meilleur compromis temps/accuracy)\n",
        "\n",
        "**Optimisations :**\n",
        "- ‚úÖ **camembert-base** au lieu de large (~3x plus rapide)\n",
        "- ‚úÖ **4 epochs** au lieu de 5 \n",
        "- ‚úÖ **batch_size=32** (2x plus rapide)\n",
        "- ‚úÖ **max_length=128** (textes plus courts)\n",
        "- ‚úÖ Architecture optimis√©e V2\n",
        "\n",
        "| Version | Temps | Accuracy |\n",
        "|---------|-------|----------|\n",
        "| V2 (large, 5 epochs) | ~50 min | 88.72% |\n",
        "| **V4 (base, 4 epochs, optimis√©)** | **~10-12 min** | **~85-86%** |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CONFIG V4 - Optimis√© temps/accuracy\n",
        "# ============================================\n",
        "CONFIG = {\n",
        "    \"model_name\": \"camembert-base\",  # Base = ~3x plus rapide que large\n",
        "    \"num_epochs\": 4,                  # 4 epochs suffisent\n",
        "    \"batch_size\": 32,                 # Plus grand = plus rapide\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"max_length\": 128,                # Suffisant pour la plupart des avis\n",
        "    \"dropout\": 0.1,\n",
        "    \"label_smoothing\": 0.1,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"warmup_ratio\": 0.1,\n",
        "    \"hidden_dim\": 256,\n",
        "    \"patience\": 2,\n",
        "}\n",
        "print(\"üìã Config V4:\", CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "print(\"Uploadez ftdataset_train.tsv et ftdataset_val.tsv:\")\n",
        "for f in files.upload().keys():\n",
        "    os.rename(f, f'/content/data/{f}')\n",
        "!ls /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModel, get_cosine_schedule_with_warmup\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "LABEL_TO_IDX = {\"Positive\": 0, \"N√©gative\": 1, \"Neutre\": 2, \"NE\": 3}\n",
        "IDX_TO_LABEL = {v: k for k, v in LABEL_TO_IDX.items()}\n",
        "ASPECTS = [\"Prix\", \"Cuisine\", \"Service\"]\n",
        "\n",
        "print(\"‚úÖ Imports OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset"
      },
      "outputs": [],
      "source": [
        "class OpinionDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, labels=None, max_length=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        self.labels = labels\n",
        "    def __len__(self): return len(self.encodings[\"input_ids\"])\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\"input_ids\": self.encodings[\"input_ids\"][idx], \"attention_mask\": self.encodings[\"attention_mask\"][idx]}\n",
        "        if self.labels:\n",
        "            for a in ASPECTS: item[f\"label_{a.lower()}\"] = torch.tensor(self.labels[a][idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "def prepare_labels(data): return {a: [LABEL_TO_IDX.get(d[a], 3) for d in data] for a in ASPECTS}\n",
        "def get_texts(data): return [d[\"Avis\"] for d in data]\n",
        "def collate_fn(f):\n",
        "    b = {\"input_ids\": torch.stack([x[\"input_ids\"] for x in f]), \"attention_mask\": torch.stack([x[\"attention_mask\"] for x in f])}\n",
        "    for a in ASPECTS:\n",
        "        k = f\"label_{a.lower()}\"\n",
        "        if k in f[0]: b[k] = torch.stack([x[k] for x in f])\n",
        "    return b\n",
        "\n",
        "print(\"‚úÖ Dataset OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model"
      },
      "outputs": [],
      "source": [
        "class OptimizedClassifier(nn.Module):\n",
        "    def __init__(self, model_name, hidden_dim=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.encoder.config.hidden_size\n",
        "        \n",
        "        # T√™tes optimis√©es avec couche cach√©e\n",
        "        self.classifiers = nn.ModuleDict({\n",
        "            a: nn.Sequential(\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_size, hidden_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim, 4)\n",
        "            ) for a in ASPECTS\n",
        "        })\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls = out.last_hidden_state[:, 0, :]\n",
        "        return {a: self.classifiers[a](cls) for a in ASPECTS}\n",
        "\n",
        "print(\"‚úÖ Mod√®le OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trainer"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"üîß Chargement de {config['model_name']}...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
        "        self.model = OptimizedClassifier(config['model_name'], config['hidden_dim'], config['dropout']).to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
        "        \n",
        "        params = sum(p.numel() for p in self.model.parameters())/1e6\n",
        "        print(f\"‚úÖ Mod√®le sur {self.device} ({params:.1f}M params)\")\n",
        "\n",
        "    def train(self, train_data, val_data):\n",
        "        cfg = self.config\n",
        "        start_time = time.time()\n",
        "        \n",
        "        train_ds = OpinionDataset(get_texts(train_data), self.tokenizer, prepare_labels(train_data), cfg['max_length'])\n",
        "        val_ds = OpinionDataset(get_texts(val_data), self.tokenizer, prepare_labels(val_data), cfg['max_length'])\n",
        "        train_loader = DataLoader(train_ds, batch_size=cfg['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "        val_loader = DataLoader(val_ds, batch_size=cfg['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
        "        \n",
        "        optimizer = AdamW(self.model.parameters(), lr=cfg['learning_rate'], weight_decay=cfg['weight_decay'])\n",
        "        total_steps = len(train_loader) * cfg['num_epochs']\n",
        "        scheduler = get_cosine_schedule_with_warmup(optimizer, int(total_steps * cfg['warmup_ratio']), total_steps)\n",
        "        \n",
        "        best_acc, best_state, patience = 0, None, 0\n",
        "        \n",
        "        for epoch in range(cfg['num_epochs']):\n",
        "            epoch_start = time.time()\n",
        "            print(f\"\\n{'='*50}\\nEpoch {epoch+1}/{cfg['num_epochs']}\\n{'='*50}\")\n",
        "            \n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "            for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "                ids, mask = batch[\"input_ids\"].to(self.device), batch[\"attention_mask\"].to(self.device)\n",
        "                logits = self.model(ids, mask)\n",
        "                loss = sum(self.criterion(logits[a], batch[f\"label_{a.lower()}\"].to(self.device)) for a in ASPECTS)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "            print(f\"Loss: {total_loss/len(train_loader):.4f}\")\n",
        "            \n",
        "            acc, details = self._eval(val_loader)\n",
        "            epoch_time = time.time() - epoch_start\n",
        "            print(f\"Val Acc: {acc:.2f}% | {details} | ‚è±Ô∏è {epoch_time:.1f}s\")\n",
        "            \n",
        "            if acc > best_acc:\n",
        "                best_acc, best_state, patience = acc, {k: v.cpu().clone() for k, v in self.model.state_dict().items()}, 0\n",
        "                print(\"‚≠ê Nouveau meilleur!\")\n",
        "            else:\n",
        "                patience += 1\n",
        "                if patience >= cfg['patience']: print(\"‚ö†Ô∏è Early stop\"); break\n",
        "        \n",
        "        if best_state: self.model.load_state_dict(best_state); self.model.to(self.device)\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"\\n{'='*50}\\nüèÜ BEST: {best_acc:.2f}% | ‚è±Ô∏è Total: {total_time/60:.1f} min\\n{'='*50}\")\n",
        "        return best_acc, total_time\n",
        "\n",
        "    def _eval(self, loader):\n",
        "        self.model.eval()\n",
        "        correct = {a: 0 for a in ASPECTS}\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                ids, mask = batch[\"input_ids\"].to(self.device), batch[\"attention_mask\"].to(self.device)\n",
        "                logits = self.model(ids, mask)\n",
        "                for a in ASPECTS:\n",
        "                    preds = torch.argmax(logits[a], dim=-1)\n",
        "                    correct[a] += (preds == batch[f\"label_{a.lower()}\"].to(self.device)).sum().item()\n",
        "                total += ids.size(0)\n",
        "        details = {a: round(100*correct[a]/total, 1) for a in ASPECTS}\n",
        "        return sum(details.values())/3, details\n",
        "\n",
        "    def predict(self, texts):\n",
        "        self.model.eval()\n",
        "        preds = []\n",
        "        for i in range(0, len(texts), 64):\n",
        "            enc = self.tokenizer(texts[i:i+64], truncation=True, padding=True, max_length=self.config['max_length'], return_tensors=\"pt\")\n",
        "            with torch.no_grad():\n",
        "                logits = self.model(enc[\"input_ids\"].to(self.device), enc[\"attention_mask\"].to(self.device))\n",
        "            for j in range(len(texts[i:i+64])):\n",
        "                preds.append({a: IDX_TO_LABEL[torch.argmax(logits[a][j]).item()] for a in ASPECTS})\n",
        "        return preds\n",
        "\n",
        "print(\"‚úÖ Trainer OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/content/data/ftdataset_train.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
        "df_val = pd.read_csv(\"/content/data/ftdataset_val.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
        "train_data, val_data = df_train.to_dict('records'), df_val.to_dict('records')\n",
        "print(f\"‚úÖ Train={len(train_data)}, Val={len(val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(CONFIG)\n",
        "best_acc, total_time = trainer.train(train_data, val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eval"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìà √âvaluation finale...\")\n",
        "preds = trainer.predict(get_texts(val_data))\n",
        "correct = {a: sum(1 for p, r in zip(preds, val_data) if p[a] == r[a]) for a in ASPECTS}\n",
        "n = len(val_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä R√âSULTATS FINAUX V4\")\n",
        "print(\"=\"*50)\n",
        "for a in ASPECTS: print(f\"  {a}: {100*correct[a]/n:.2f}%\")\n",
        "macro = sum(100*correct[a]/n for a in ASPECTS)/3\n",
        "print(f\"\\nüéØ MACRO ACCURACY: {macro:.2f}%\")\n",
        "print(f\"‚è±Ô∏è Temps total: {total_time/60:.1f} min\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test"
      },
      "outputs": [],
      "source": [
        "test_texts = [\n",
        "    \"Excellente cuisine, plats savoureux. Service un peu lent mais correct. Prix raisonnables.\",\n",
        "    \"Tr√®s d√©√ßu. Nourriture froide et serveur d√©sagr√©able. Bien trop cher.\",\n",
        "    \"Bon rapport qualit√©-prix. Service efficace. Cuisine correcte.\"\n",
        "]\n",
        "print(\"üß™ Test:\\n\")\n",
        "for t, p in zip(test_texts, trainer.predict(test_texts)):\n",
        "    print(f\"'{t[:50]}...'\\n  ‚Üí {p}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save"
      },
      "outputs": [],
      "source": [
        "torch.save({'model': trainer.model.state_dict(), 'config': CONFIG, 'acc': best_acc, 'time': total_time}, '/content/model_v4_optimized.pt')\n",
        "print(f\"‚úÖ Sauvegard√© (acc: {best_acc:.2f}%, temps: {total_time/60:.1f} min)\")\n",
        "from google.colab import files\n",
        "files.download('/content/model_v4_optimized.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {"gpuType": "T4", "provenance": []},
    "kernelspec": {"display_name": "Python 3", "name": "python3"}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
